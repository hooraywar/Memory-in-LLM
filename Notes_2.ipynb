{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Buffer Memory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11979/3461632742.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0) # temp = 0 is to avoid hallucination\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0) # temp = 0 is to avoid hallucination\n",
    "\n",
    "#Model hallucination occurs when an AI model generates incorrect or fabricated information that is not based on the input data or underlying knowledge. In simpler terms, the model \"makes up\" details or facts that are inaccurate or imaginary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I cannot remember any secret codes as I am a computer program and do not have the ability to retain personal information.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you remember your secrete code that is : Hooria?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Canada is Ottawa.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"what is the capital of canada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have the ability to remember secret codes or any personal information.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"do you remember the secret code? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferMemory() # temp = 0 is to avoid hallucination\n",
    "\n",
    "conversation = ConversationChain(\n",
    "\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Can you remember your secrete code that is : Hooria?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, I can remember the secret code \"Hooria.\" It is a unique identifier that helps me access certain information or perform specific tasks.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can you remember your secrete code that is : Hooria?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Can you remember your secrete code that is : Hooria?\n",
      "AI: Yes, I can remember the secret code \"Hooria.\" It is a unique identifier that helps me access certain information or perform specific tasks.\n",
      "Human: what is the capital of canada?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Canada is Ottawa. It is located in the province of Ontario and is known for its historic architecture, government buildings, and cultural attractions.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is the capital of canada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Can you remember your secrete code that is : Hooria?\n",
      "AI: Yes, I can remember the secret code \"Hooria.\" It is a unique identifier that helps me access certain information or perform specific tasks.\n",
      "Human: what is the capital of canada?\n",
      "AI: The capital of Canada is Ottawa. It is located in the province of Ontario and is known for its historic architecture, government buildings, and cultural attractions.\n",
      "Human: do you remember the secret code? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, I remember the secret code \"Hooria.\" It is still stored in my memory for future reference.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"do you remember the secret code? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## operation on memory of llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Can you remember your secrete code that is : Hooria?\n",
      "AI: Yes, I can remember the secret code \"Hooria.\" It is a unique identifier that helps me access certain information or perform specific tasks.\n",
      "Human: what is the capital of canada?\n",
      "AI: The capital of Canada is Ottawa. It is located in the province of Ontario and is known for its historic architecture, government buildings, and cultural attractions.\n",
      "Human: do you remember the secret code? \n",
      "AI: Yes, I remember the secret code \"Hooria.\" It is still stored in my memory for future reference.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer) ## stores ptrevious conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Can you remember your secrete code that is : Hooria?\\nAI: Yes, I can remember the secret code \"Hooria.\" It is a unique identifier that helps me access certain information or perform specific tasks.\\nHuman: what is the capital of canada?\\nAI: The capital of Canada is Ottawa. It is located in the province of Ontario and is known for its historic architecture, government buildings, and cultural attractions.\\nHuman: do you remember the secret code? \\nAI: Yes, I remember the secret code \"Hooria.\" It is still stored in my memory for future reference.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({}) ## to get the prevoiius conversation in dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'input': \"What is the capital of England? \"}, \n",
    "                    {\"output\": \"London\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Can you remember your secrete code that is : Hooria?\n",
      "AI: Yes, I can remember the secret code \"Hooria.\" It is a unique identifier that helps me access certain information or perform specific tasks.\n",
      "Human: what is the capital of canada?\n",
      "AI: The capital of Canada is Ottawa. It is located in the province of Ontario and is known for its historic architecture, government buildings, and cultural attractions.\n",
      "Human: do you remember the secret code? \n",
      "AI: Yes, I remember the secret code \"Hooria.\" It is still stored in my memory for future reference.\n",
      "Human: What is the capital of England? \n",
      "AI: London\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11979/2518080587.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=70)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=70)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "AI: Hello! Yes, I remember the secret word is cat. How can I assist you today?\n",
      "Human: do you remember the secret word?!\n",
      "AI: Yes, the secret word is cat! How can I help you with that today?\n",
      "Human: Hi, remember the secret word is cat!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! Yes, I remember the secret word is cat. How can I assist you today?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi, remember the secret word is cat!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: do you remember the secret word?!\n",
      "AI: I'm sorry, I do not have the ability to remember secret words. Is there anything else I can help you with?\n",
      "Human: what was the day on 13th of october 1997 ?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The 13th of October 1997 was a Monday. Is there anything else you would like to know about that date?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what was the day on 13th of october 1997 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: what was the day on 13th of october 1994 ?\n",
      "AI: The day on October 13, 1994, was a Thursday. Is there anything else you would like to know?\n",
      "Human: do you remember the secret word?!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have the ability to remember secret words. Is there anything else I can help you with?\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='do you remember the secret word?!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Token Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11979/3112362828.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"Detective Marlowe was on the case of a stolen 17th-century portrait from a prestigious city art gallery. \\\n",
    " In a whirlwind investigation, he linked a suspicious glitch in the gallery's security system, an unusually jittery \\\n",
    "  night watchman, and an enigmatic foreign buyer showing keen interest in the artwork. Delving deeper, Marlowe \\\n",
    "   discovered the portrait concealed a map to a lost treasure, which led him to an underground art-smuggling ring. \\\n",
    "    With skillful sleuthing and relentless determination, Marlowe solved the mystery, brought the criminals to justice, \\\n",
    "     and ensured the priceless artwork was rightfully restored.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Write a crime story?\"}, \n",
    "                    {\"output\": f\"{story}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks the AI to write a crime story, and the AI creates a tale about Detective Marlowe solving the case of a stolen 17th-century portrait, uncovering an underground art-smuggling ring, and bringing the criminals to justice.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI to write a crime story, and the AI creates a tale about Detective Marlowe solving the case of a stolen 17th-century portrait, uncovering an underground art-smuggling ring, and bringing the criminals to justice.\n",
      "Human: What artifact was stolen?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The stolen artifact in the crime story was a 17th-century portrait of a noblewoman, rumored to be worth millions on the black market.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What artifact was stolen?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks the AI to write a crime story, and the AI creates a tale about Detective Marlowe solving the case of a stolen 17th-century portrait, uncovering an underground art-smuggling ring, and bringing the criminals to justice.\\nHuman: What artifact was stolen?\\nAI: The stolen artifact in the crime story was a 17th-century portrait of a noblewoman, rumored to be worth millions on the black market.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI to write a crime story, and the AI creates a tale about Detective Marlowe solving the case of a stolen 17th-century portrait, uncovering an underground art-smuggling ring, and bringing the criminals to justice.\n",
      "Human: What artifact was stolen?\n",
      "AI: The stolen artifact in the crime story was a 17th-century portrait of a noblewoman, rumored to be worth millions on the black market.\n",
      "Human: Tell me about the capital of France?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris, known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, cuisine, and rich history dating back to Roman times. It is a major global city and a hub for culture, fashion, and commerce.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Tell me about the capital of France?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks the AI to write a crime story, and the AI creates a tale about Detective Marlowe solving the case of a stolen 17th-century portrait, uncovering an underground art-smuggling ring, and bringing the criminals to justice. The stolen artifact in the crime story was a 17th-century portrait of a noblewoman, rumored to be worth millions on the black market.\\nHuman: Tell me about the capital of France?\\nAI: The capital of France is Paris, known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, cuisine, and rich history dating back to Roman times. It is a major global city and a hub for culture, fashion, and commerce.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
